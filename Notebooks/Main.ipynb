{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f21f97-de22-4ece-90f2-ed2a1324f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from skimage import io\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, classification_report, mean_absolute_error\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Activation, Dropout, Flatten, Dense, Dropout, LayerNormalization, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7da6ae12-809d-45f4-975e-bb49a116b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset is divided in 4 files, this concatenates them all\n",
    "df_list = []\n",
    "for file_name in glob.glob(\"../Data/Raw/Archive/*.txt\"):\n",
    "    df_temp = pd.read_csv(file_name, sep=\"\\t\")\n",
    "    df_list.append(df_temp)\n",
    "df = pd.concat(df_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2774adf7-7eae-44bc-8ed3-6f09886cd6f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>original_image</th>\n",
       "      <th>face_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>tilt_ang</th>\n",
       "      <th>fiducial_yaw_angle</th>\n",
       "      <th>fiducial_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10399646885_67c7d20df9_o.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>1086</td>\n",
       "      <td>1383</td>\n",
       "      <td>-115</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10424815813_e94629b1ec_o.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>301</td>\n",
       "      <td>105</td>\n",
       "      <td>640</td>\n",
       "      <td>641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10437979845_5985be4b26_o.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>f</td>\n",
       "      <td>2395</td>\n",
       "      <td>876</td>\n",
       "      <td>771</td>\n",
       "      <td>771</td>\n",
       "      <td>175</td>\n",
       "      <td>-30</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>10437979845_5985be4b26_o.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>752</td>\n",
       "      <td>1255</td>\n",
       "      <td>484</td>\n",
       "      <td>485</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30601258@N03</td>\n",
       "      <td>11816644924_075c3d8d59_o.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>(25, 32)</td>\n",
       "      <td>m</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>769</td>\n",
       "      <td>768</td>\n",
       "      <td>-75</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19365</th>\n",
       "      <td>7153718@N04</td>\n",
       "      <td>11598838386_349a0d4849_o.jpg</td>\n",
       "      <td>2282</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>596</td>\n",
       "      <td>460</td>\n",
       "      <td>1472</td>\n",
       "      <td>1473</td>\n",
       "      <td>-75</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19366</th>\n",
       "      <td>7153718@N04</td>\n",
       "      <td>11598166203_c70bb34c80_o.jpg</td>\n",
       "      <td>2283</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1179</td>\n",
       "      <td>755</td>\n",
       "      <td>331</td>\n",
       "      <td>331</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19367</th>\n",
       "      <td>7153718@N04</td>\n",
       "      <td>11598166203_c70bb34c80_o.jpg</td>\n",
       "      <td>2282</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1201</td>\n",
       "      <td>1179</td>\n",
       "      <td>293</td>\n",
       "      <td>293</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19368</th>\n",
       "      <td>7153718@N04</td>\n",
       "      <td>11598145163_733cb99713_o.jpg</td>\n",
       "      <td>2282</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027</td>\n",
       "      <td>946</td>\n",
       "      <td>408</td>\n",
       "      <td>408</td>\n",
       "      <td>-85</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19369</th>\n",
       "      <td>7153718@N04</td>\n",
       "      <td>11598013005_240c2bc9c7_o.jpg</td>\n",
       "      <td>2282</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>498</td>\n",
       "      <td>643</td>\n",
       "      <td>772</td>\n",
       "      <td>772</td>\n",
       "      <td>-80</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19370 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id                original_image  face_id       age gender  \\\n",
       "0      30601258@N03  10399646885_67c7d20df9_o.jpg        1  (25, 32)      f   \n",
       "1      30601258@N03  10424815813_e94629b1ec_o.jpg        2  (25, 32)      m   \n",
       "2      30601258@N03  10437979845_5985be4b26_o.jpg        1  (25, 32)      f   \n",
       "3      30601258@N03  10437979845_5985be4b26_o.jpg        3  (25, 32)      m   \n",
       "4      30601258@N03  11816644924_075c3d8d59_o.jpg        2  (25, 32)      m   \n",
       "...             ...                           ...      ...       ...    ...   \n",
       "19365   7153718@N04  11598838386_349a0d4849_o.jpg     2282      None    NaN   \n",
       "19366   7153718@N04  11598166203_c70bb34c80_o.jpg     2283      None    NaN   \n",
       "19367   7153718@N04  11598166203_c70bb34c80_o.jpg     2282      None    NaN   \n",
       "19368   7153718@N04  11598145163_733cb99713_o.jpg     2282      None    NaN   \n",
       "19369   7153718@N04  11598013005_240c2bc9c7_o.jpg     2282      None    NaN   \n",
       "\n",
       "          x     y    dx    dy  tilt_ang  fiducial_yaw_angle  fiducial_score  \n",
       "0         0   414  1086  1383      -115                  30              17  \n",
       "1       301   105   640   641         0                   0              94  \n",
       "2      2395   876   771   771       175                 -30              74  \n",
       "3       752  1255   484   485       180                   0              47  \n",
       "4       175    80   769   768       -75                   0              34  \n",
       "...     ...   ...   ...   ...       ...                 ...             ...  \n",
       "19365   596   460  1472  1473       -75                   0              30  \n",
       "19366  1179   755   331   331         5                   0             108  \n",
       "19367  1201  1179   293   293         5                   0              99  \n",
       "19368  1027   946   408   408       -85                   0              49  \n",
       "19369   498   643   772   772       -80                   0             111  \n",
       "\n",
       "[19370 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9cb4e1e-2af8-4511-90c7-15bcff507f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30c3bbc-d3b8-4efc-9e2b-ba9803bd170a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 32)     4953\n",
       "(0, 2)       2488\n",
       "(38, 43)     2293\n",
       "(4, 6)       2140\n",
       "(8, 12)      2119\n",
       "(15, 20)     1642\n",
       "(60, 100)     867\n",
       "(48, 53)      825\n",
       "35            293\n",
       "13            168\n",
       "22            149\n",
       "34            105\n",
       "23             96\n",
       "45             88\n",
       "(27, 32)       77\n",
       "55             76\n",
       "36             56\n",
       "(38, 42)       46\n",
       "None           40\n",
       "57             24\n",
       "3              18\n",
       "29             11\n",
       "(38, 48)        6\n",
       "58              5\n",
       "2               3\n",
       "(8, 23)         1\n",
       "42              1\n",
       "46              1\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"age\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b248b12-fd0a-43b2-9341-8fded9660176",
   "metadata": {},
   "source": [
    "Age map to use for regression, this dataset is meant to make the age a classification problem, but we are going to make it a regression one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928505ab-0f0a-45c8-acf2-5d7fc8fd0758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[df[\"age\"] != \"None\"]\n",
    "\n",
    "ages_map = {}\n",
    "ages_keys = df[\"age\"].value_counts().index\n",
    "ages_values = []\n",
    "\n",
    "for x in df[\"age\"].value_counts().index:\n",
    "    if x.startswith(\"(\"):\n",
    "        x = x.split(\", \")\n",
    "        x[0] = x[0].replace(\"(\",\"\")\n",
    "        x[1] = x[1].replace(\")\",\"\")\n",
    "        x[0] = int(x[0])\n",
    "        x[1] = int(x[1])\n",
    "        x = int((x[0]+x[1])/2)\n",
    "        ages_values.append(x)\n",
    "    else:\n",
    "        ages_values.append(int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d2133fd-f23a-4d97-8390-6c42f84a0095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, value in zip(ages_keys, ages_values):\n",
    "    ages_map[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bcebb7a-247c-4e57-b969-e6ade2d4b7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"age\"] = df[\"age\"].map(ages_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc56400a-17ae-4bb7-bc11-678f9449a933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f    9332\n",
       "m    8120\n",
       "u    1099\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b15e616-ab11-4ab7-aa06-0f279477edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will later make the model predict a non-binary category\n",
    "\n",
    "df = df[df[\"gender\"] != \"u\"]\n",
    "df[\"gender\"] = df[\"gender\"].apply(lambda x: 1 if x == \"m\" else 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c925dce8-5a77-42d6-acb1-d6f5cad01576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the path to the image\n",
    "\n",
    "df[\"face_id\"] = df[\"face_id\"].astype(str)\n",
    "df[\"path\"] = \"../Data/Raw/Archive/Faces/\"+df[\"user_id\"]+\"/coarse_tilt_aligned_face.\"+df[\"face_id\"]+\".\"+df[\"original_image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "804f818a-10b3-450e-9ccd-b04c2266177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/Clean/Faces.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f0159e7-dab5-4ac0-a5bf-5b66db5ba79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"path\"]\n",
    "y_age = df[\"age\"]\n",
    "y_gender = df[\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abf36d3b-8ca2-4903-bd4c-966a936580f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_age, y_test_age = train_test_split(X, y_age, test_size = 0.22, random_state = 22)\n",
    "X_train, X_test, y_train_gender, y_test_gender = train_test_split(X, y_gender, test_size = 0.22, random_state = 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619bd733-f24d-455e-8093-2fd7d332af92",
   "metadata": {},
   "source": [
    "Image greyscaled, downscaled, size adjusted and transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a10847a6-9c0e-4402-baae-3b7f201a891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(path):\n",
    "    img = tf.io.read_file(np.array(path).ravel()[0])\n",
    "    img = tf.image.decode_jpeg(img, channels = 1, ratio = 2)\n",
    "    img = tf.image.resize(img, [64,64])\n",
    "    img = img / 255 # This part normalizes the image, scaling it down; 255 is the max, while 0 is the min\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d4a64fc-df39-41c7-8e34-bbad7cd6ecf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ea60d4fdf0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_preprocess(df[\"path\"][22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e636d2a-213a-4dba-ad96-0433280cbf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data that will be fed to the model\n",
    "\n",
    "X_train_images = np.array([image_preprocess(path) for path in X_train])\n",
    "X_test_images = np.array([image_preprocess(path) for path in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1eee5705-96b1-4f21-9e5b-4e54f2e31497",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../Data/Clean/X_train_images.pkl\"\n",
    "with open(filename, \"wb\") as file:\n",
    "    pickle.dump(X_train_images, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00280792-7976-4a63-947b-84faef77a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../Data/Clean/X_test_images.pkl\"\n",
    "with open(filename, \"wb\") as file:\n",
    "    pickle.dump(X_test_images, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d11f07b-5463-4572-987f-3cecc56a4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This changes the learning rate based on epochs\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr - (lr/(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a02f0314-f53b-46fa-98c1-60bd7c7072d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 63, 63, 64)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 15, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        16448     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                200768    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 234,049\n",
      "Trainable params: 234,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_age = Sequential()\n",
    "# First layer needs as many nodes as inputs\n",
    "model_age.add(Conv2D(64,(2,2), activation = \"relu\", input_shape = (64,64,1)))\n",
    "model_age.add(MaxPool2D((2,2)))\n",
    "model_age.add(Conv2D(64,(2,2), activation = \"relu\"))\n",
    "model_age.add(MaxPool2D((2,2)))\n",
    "model_age.add(Conv2D(64,(2,2), activation = \"relu\"))\n",
    "model_age.add(MaxPool2D((2,2)))\n",
    "model_age.add(Flatten())\n",
    "model_age.add(Dense(64, activation = \"relu\"))\n",
    "model_age.add(Dense(1, activation = \"relu\"))\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.01)\n",
    "model_age.compile(optimizer = opt,\n",
    "              loss = \"mse\",\n",
    "              metrics = [\"mae\", \"mse\", \"mape\"])\n",
    "model_age.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7304ed8a-6a6c-4fd9-8f84-beeca348d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=5)\n",
    "\n",
    "checkpoint_path = '../Models/Age_NN6.hdf5'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_freq='epoch',\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c58fb3-1ab8-4d14-8d20-2b12df94e0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: saving model to ../Models\\Age_NN6.hdf5\n",
      "107/107 - 72s - loss: 924.0138 - mae: 23.7823 - mse: 924.0138 - mape: 104.6028 - val_loss: 723.0570 - val_mae: 20.1978 - val_mse: 723.0570 - val_mape: 99.8579 - lr: 0.0100 - 72s/epoch - 672ms/step\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: saving model to ../Models\\Age_NN6.hdf5\n",
      "107/107 - 73s - loss: 499.1007 - mae: 16.8535 - mse: 499.1007 - mape: 175.2074 - val_loss: 356.9782 - val_mae: 14.6514 - val_mse: 356.9782 - val_mape: 265.8598 - lr: 0.0100 - 73s/epoch - 683ms/step\n",
      "Epoch 3/100\n"
     ]
    }
   ],
   "source": [
    "history = model_age.fit(\n",
    "    X_train_images, y_train_age,\n",
    "    epochs=100,\n",
    "    validation_data = (X_test_images, y_test_age),\n",
    "    batch_size=128,\n",
    "    verbose=2,\n",
    "    callbacks=[early_stop, checkpoint, schedule]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "77734416-a0cb-4e17-87c9-4e74b69aee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 14s 33ms/step\n",
      "120/120 [==============================] - 4s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.07074832626819"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10.022828334585453"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_pred = model_age.predict(X_train_images)\n",
    "y_test_pred  = model_age.predict(X_test_images)\n",
    "\n",
    "display(mean_absolute_error(y_train_age,y_train_pred))\n",
    "display(mean_absolute_error(y_test_age,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "7ad661ad-49a8-4550-bc83-fc1ea3cbe4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_age = load_model(\"../Models/Age_NN3.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "d7d344db-5724-44d4-8a5f-6383d3fcad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 22s 51ms/step\n",
      "120/120 [==============================] - 6s 48ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.357551175066471"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7.97575630665912"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_pred = model_age.predict(X_train_images)\n",
    "y_test_pred  = model_age.predict(X_test_images)\n",
    "\n",
    "display(mean_absolute_error(y_train_age,y_train_pred))\n",
    "display(mean_absolute_error(y_test_age,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ac4ae-f63d-4bce-a534-c04026782913",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6ca7755c-b2f6-443e-8da1-228776e5304e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_165 (Conv2D)         (None, 63, 63, 64)        320       \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 31, 31, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_166 (Conv2D)         (None, 30, 30, 64)        16448     \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 15, 15, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_167 (Conv2D)         (None, 14, 14, 64)        16448     \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 7, 7, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_30 (Flatten)        (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 64)                200768    \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 234,049\n",
      "Trainable params: 234,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_gender = Sequential()\n",
    "# First layer needs as many nodes as inputs\n",
    "model_gender.add(Conv2D(64,(2,2), activation = \"relu\", input_shape = (64,64,1)))\n",
    "model_gender.add(MaxPool2D((2,2)))\n",
    "model_gender.add(Conv2D(64,(2,2), activation = \"relu\"))\n",
    "model_gender.add(MaxPool2D((2,2)))\n",
    "model_gender.add(Conv2D(64,(2,2), activation = \"relu\"))\n",
    "model_gender.add(MaxPool2D((2,2)))\n",
    "model_gender.add(Flatten())\n",
    "model_gender.add(Dense(64, activation = \"relu\"))\n",
    "model_gender.add(Dense(1, activation = \"sigmoid\"))\n",
    "model_gender.compile(optimizer = \"adam\",\n",
    "              loss = \"binary_crossentropy\",\n",
    "              metrics = \"accuracy\")\n",
    "model_gender.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f858a1ca-1253-4b80-a88b-24fb9f8d638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=5)\n",
    "\n",
    "checkpoint_path = '../Models/Gender_NN14.hdf5'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_freq='epoch',\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "schedule = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d349ff10-a077-4f1b-b150-29623cabae6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 1: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 51s - loss: 0.6152 - accuracy: 0.6488 - val_loss: 0.5823 - val_accuracy: 0.6992 - lr: 0.0010 - 51s/epoch - 473ms/step\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 2: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 53s - loss: 0.5278 - accuracy: 0.7348 - val_loss: 0.5298 - val_accuracy: 0.7354 - lr: 0.0010 - 53s/epoch - 495ms/step\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 3: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 51s - loss: 0.4695 - accuracy: 0.7752 - val_loss: 0.4835 - val_accuracy: 0.7685 - lr: 0.0010 - 51s/epoch - 476ms/step\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 4: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 50s - loss: 0.4340 - accuracy: 0.7969 - val_loss: 0.4531 - val_accuracy: 0.7901 - lr: 0.0010 - 50s/epoch - 467ms/step\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 5: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 51s - loss: 0.3968 - accuracy: 0.8205 - val_loss: 0.4207 - val_accuracy: 0.8076 - lr: 0.0010 - 51s/epoch - 474ms/step\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 6: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 56s - loss: 0.3663 - accuracy: 0.8377 - val_loss: 0.4066 - val_accuracy: 0.8190 - lr: 9.0000e-04 - 56s/epoch - 522ms/step\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 7: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 55s - loss: 0.3349 - accuracy: 0.8508 - val_loss: 0.3985 - val_accuracy: 0.8273 - lr: 8.2500e-04 - 55s/epoch - 514ms/step\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 8: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 63s - loss: 0.3129 - accuracy: 0.8636 - val_loss: 0.4016 - val_accuracy: 0.8227 - lr: 7.6607e-04 - 63s/epoch - 587ms/step\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 9: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 57s - loss: 0.2857 - accuracy: 0.8771 - val_loss: 0.3686 - val_accuracy: 0.8424 - lr: 7.1819e-04 - 57s/epoch - 529ms/step\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 10: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 58s - loss: 0.2682 - accuracy: 0.8851 - val_loss: 0.3579 - val_accuracy: 0.8430 - lr: 6.7829e-04 - 58s/epoch - 546ms/step\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 11: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 58s - loss: 0.2515 - accuracy: 0.8963 - val_loss: 0.3639 - val_accuracy: 0.8440 - lr: 6.4438e-04 - 58s/epoch - 545ms/step\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 12: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 64s - loss: 0.2336 - accuracy: 0.9026 - val_loss: 0.3773 - val_accuracy: 0.8388 - lr: 6.1509e-04 - 64s/epoch - 601ms/step\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 13: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 56s - loss: 0.2249 - accuracy: 0.9053 - val_loss: 0.3595 - val_accuracy: 0.8487 - lr: 5.8946e-04 - 56s/epoch - 519ms/step\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 14: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 62s - loss: 0.2028 - accuracy: 0.9161 - val_loss: 0.3675 - val_accuracy: 0.8464 - lr: 5.6679e-04 - 62s/epoch - 575ms/step\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 15: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 57s - loss: 0.1908 - accuracy: 0.9217 - val_loss: 0.3572 - val_accuracy: 0.8508 - lr: 5.4655e-04 - 57s/epoch - 537ms/step\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 16: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 57s - loss: 0.1862 - accuracy: 0.9229 - val_loss: 0.3756 - val_accuracy: 0.8510 - lr: 5.2833e-04 - 57s/epoch - 534ms/step\n",
      "Epoch 17/50\n",
      "\n",
      "Epoch 17: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 57s - loss: 0.1706 - accuracy: 0.9310 - val_loss: 0.3758 - val_accuracy: 0.8526 - lr: 5.1182e-04 - 57s/epoch - 535ms/step\n",
      "Epoch 18/50\n",
      "\n",
      "Epoch 18: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 58s - loss: 0.1554 - accuracy: 0.9402 - val_loss: 0.3781 - val_accuracy: 0.8518 - lr: 4.9676e-04 - 58s/epoch - 538ms/step\n",
      "Epoch 19/50\n",
      "\n",
      "Epoch 19: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 58s - loss: 0.1451 - accuracy: 0.9439 - val_loss: 0.3944 - val_accuracy: 0.8490 - lr: 4.8296e-04 - 58s/epoch - 540ms/step\n",
      "Epoch 20/50\n",
      "\n",
      "Epoch 20: saving model to ../Models\\Gender_NN14.hdf5\n",
      "107/107 - 57s - loss: 0.1355 - accuracy: 0.9486 - val_loss: 0.3914 - val_accuracy: 0.8484 - lr: 4.7025e-04 - 57s/epoch - 532ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model_gender.fit(\n",
    "    X_train_images, y_train_gender,\n",
    "    epochs=50,\n",
    "    validation_data = (X_test_images, y_test_gender),\n",
    "    batch_size=128,\n",
    "    verbose=2,\n",
    "    callbacks=[early_stop, checkpoint, schedule]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c289d592-2279-48c7-a890-ecde12daa3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 15s 35ms/step\n",
      "120/120 [==============================] - 4s 35ms/step\n",
      "Kappa score: 0.9123469090040686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      7317\n",
      "           1       0.96      0.95      0.95      6295\n",
      "\n",
      "    accuracy                           0.96     13612\n",
      "   macro avg       0.96      0.96      0.96     13612\n",
      "weighted avg       0.96      0.96      0.96     13612\n",
      "\n",
      "Kappa score: 0.6962566205341549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86      2015\n",
      "           1       0.84      0.84      0.84      1825\n",
      "\n",
      "    accuracy                           0.85      3840\n",
      "   macro avg       0.85      0.85      0.85      3840\n",
      "weighted avg       0.85      0.85      0.85      3840\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.30743808]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.57551116]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4375831]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.61811656]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.77895784]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00361885]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00406393]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.12396926]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.1857658]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0554034]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.61759406]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.79290736]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_pred = model_gender.predict(X_train_images)\n",
    "y_test_pred  = model_gender.predict(X_test_images)\n",
    "\n",
    "\n",
    "# This is for binary_crossentropy (1 neuron final output)\n",
    "y_train_pred2 = [int(round(y_train_pred[x][0],0)) for x in range(len(y_train_pred))]\n",
    "y_test_pred2 = [int(round(y_test_pred[x][0],0)) for x in range(len(y_test_pred))]\n",
    "\n",
    "\n",
    "# This is for sparse_categorical_crossestropy (2 neurons final output)\n",
    "# y_train_pred2 = np.argmax(y_train_pred, axis=1).reshape(-1,1)\n",
    "# y_test_pred2 = np.argmax(y_test_pred, axis=1).reshape(-1,1)\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model_gender.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7126a466-a750-46ba-8135-976df36a24de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "787a8e60-2e88-465b-b0a1-8a10f8eff757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 20s 46ms/step\n",
      "120/120 [==============================] - 5s 45ms/step\n",
      "Kappa score: 0.9603125693479869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      7317\n",
      "           1       0.99      0.96      0.98      6295\n",
      "\n",
      "    accuracy                           0.98     13612\n",
      "   macro avg       0.98      0.98      0.98     13612\n",
      "weighted avg       0.98      0.98      0.98     13612\n",
      "\n",
      "Kappa score: 0.7135060608586455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      2015\n",
      "           1       0.89      0.80      0.84      1825\n",
      "\n",
      "    accuracy                           0.86      3840\n",
      "   macro avg       0.86      0.85      0.86      3840\n",
      "weighted avg       0.86      0.86      0.86      3840\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00496252]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.46562913]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00355448]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.027608]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.12322083]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00957087]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9703398]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.4654832e-06]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.07899495]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00011965]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.12507984]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06703958]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN1.hdf5')\n",
    "\n",
    "y_train_pred = model.predict(X_train_images)\n",
    "y_test_pred  = model.predict(X_test_images)\n",
    "\n",
    "y_train_pred2 = [int(round(y_train_pred[x][0],0)) for x in range(len(y_train_pred))]\n",
    "y_test_pred2 = [int(round(y_test_pred[x][0],0)) for x in range(len(y_test_pred))]\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "658f16b1-8f63-43a7-baf4-61b9ea51f14b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 16s 37ms/step\n",
      "120/120 [==============================] - 4s 37ms/step\n",
      "Kappa score: 0.899815112283669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      7317\n",
      "           1       0.94      0.96      0.95      6295\n",
      "\n",
      "    accuracy                           0.95     13612\n",
      "   macro avg       0.95      0.95      0.95     13612\n",
      "weighted avg       0.95      0.95      0.95     13612\n",
      "\n",
      "Kappa score: 0.6843100805531096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85      2015\n",
      "           1       0.83      0.84      0.84      1825\n",
      "\n",
      "    accuracy                           0.84      3840\n",
      "   macro avg       0.84      0.84      0.84      3840\n",
      "weighted avg       0.84      0.84      0.84      3840\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9916688]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.14759696]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.37386474]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00217511]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.09738189]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00863037]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.20059496]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00031576]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6929264]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.12973307]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00083649]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01781248]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN2.hdf5')\n",
    "\n",
    "y_train_pred = model.predict(X_train_images)\n",
    "y_test_pred  = model.predict(X_test_images)\n",
    "\n",
    "y_train_pred2 = [int(round(y_train_pred[x][0],0)) for x in range(len(y_train_pred))]\n",
    "y_test_pred2 = [int(round(y_test_pred[x][0],0)) for x in range(len(y_test_pred))]\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a95a06dd-44f5-444c-82e3-25141cec61c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 24s 55ms/step\n",
      "120/120 [==============================] - 9s 74ms/step\n",
      "Kappa score: 0.9613240793942013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      7317\n",
      "           1       0.97      0.99      0.98      6295\n",
      "\n",
      "    accuracy                           0.98     13612\n",
      "   macro avg       0.98      0.98      0.98     13612\n",
      "weighted avg       0.98      0.98      0.98     13612\n",
      "\n",
      "Kappa score: 0.7388336677373024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87      2015\n",
      "           1       0.85      0.88      0.86      1825\n",
      "\n",
      "    accuracy                           0.87      3840\n",
      "   macro avg       0.87      0.87      0.87      3840\n",
      "weighted avg       0.87      0.87      0.87      3840\n",
      "\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7225587 , 0.47037253]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.61995155, 0.13939387]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0558153, 0.9033253]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9932083 , 0.01173154]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.15030806, 0.9099361 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.86575  , 0.0824468]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.84765184, 0.33214435]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6272185 , 0.00441729]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8283349, 0.2126803]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8788509 , 0.00777648]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.93306607, 0.12620154]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00160575, 0.99948037]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN3.hdf5')\n",
    "\n",
    "y_train_pred = model.predict(X_train_images)\n",
    "y_test_pred  = model.predict(X_test_images)\n",
    "\n",
    "y_train_pred2 = np.argmax(y_train_pred, axis=1).reshape(-1,1)\n",
    "y_test_pred2 = np.argmax(y_test_pred, axis=1).reshape(-1,1)\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b526e7ef-4e3d-4399-b3b5-e1b37b522a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 62, 62, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 31, 31, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 29, 29, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                147520    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 222,146\n",
      "Trainable params: 222,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN3.hdf5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1c3c1144-98a9-4805-b436-b7f0bfea22f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 24s 56ms/step\n",
      "120/120 [==============================] - 6s 53ms/step\n",
      "Kappa score: 0.9590993829312577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      7317\n",
      "           1       0.97      0.98      0.98      6295\n",
      "\n",
      "    accuracy                           0.98     13612\n",
      "   macro avg       0.98      0.98      0.98     13612\n",
      "weighted avg       0.98      0.98      0.98     13612\n",
      "\n",
      "Kappa score: 0.7131794841848091\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      2015\n",
      "           1       0.84      0.86      0.85      1825\n",
      "\n",
      "    accuracy                           0.86      3840\n",
      "   macro avg       0.86      0.86      0.86      3840\n",
      "weighted avg       0.86      0.86      0.86      3840\n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.81640667, 0.16566283]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5625996, 0.3058516]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.776033e-05, 9.933044e-01]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.19767766, 0.1708729 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5218073 , 0.18126762]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6058299 , 0.22640173]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.46107364, 0.35099173]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9431572 , 0.01587466]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.23118146, 0.8365652 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.94889736, 0.00422811]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.80444604, 0.09951599]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5174379 , 0.47402468]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN4.hdf5')\n",
    "\n",
    "y_train_pred = model.predict(X_train_images)\n",
    "y_test_pred  = model.predict(X_test_images)\n",
    "\n",
    "y_train_pred2 = np.argmax(y_train_pred, axis=1).reshape(-1,1)\n",
    "y_test_pred2 = np.argmax(y_test_pred, axis=1).reshape(-1,1)\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e8a50dc5-84a2-47df-957d-0f23e4c64970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 24s 57ms/step\n",
      "120/120 [==============================] - 6s 52ms/step\n",
      "Kappa score: 0.9764977378273978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      7317\n",
      "           1       0.99      0.98      0.99      6295\n",
      "\n",
      "    accuracy                           0.99     13612\n",
      "   macro avg       0.99      0.99      0.99     13612\n",
      "weighted avg       0.99      0.99      0.99     13612\n",
      "\n",
      "Kappa score: 0.7096159521902163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      2015\n",
      "           1       0.85      0.84      0.85      1825\n",
      "\n",
      "    accuracy                           0.86      3840\n",
      "   macro avg       0.85      0.85      0.85      3840\n",
      "weighted avg       0.86      0.86      0.86      3840\n",
      "\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9346781, 0.0792326]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.90897983, 0.07980809]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.1871629e-04, 9.9434811e-01]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.17192067, 0.23709632]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7158851, 0.1166004]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.78329706, 0.13463211]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48913893, 0.37295684]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9612221 , 0.01328603]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2838027, 0.8095498]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.97720236, 0.00173001]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.92478395, 0.05431846]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.59003854, 0.6343046 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN5.hdf5')\n",
    "\n",
    "y_train_pred = model.predict(X_train_images)\n",
    "y_test_pred  = model.predict(X_test_images)\n",
    "\n",
    "y_train_pred2 = np.argmax(y_train_pred, axis=1).reshape(-1,1)\n",
    "y_test_pred2 = np.argmax(y_test_pred, axis=1).reshape(-1,1)\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f1f56b9f-6556-4820-a964-9393bf4d59cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 22s 52ms/step\n",
      "120/120 [==============================] - 5s 45ms/step\n",
      "Kappa score: 0.7382755135116543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      7317\n",
      "           1       0.86      0.86      0.86      6295\n",
      "\n",
      "    accuracy                           0.87     13612\n",
      "   macro avg       0.87      0.87      0.87     13612\n",
      "weighted avg       0.87      0.87      0.87     13612\n",
      "\n",
      "Kappa score: 0.6374297807267567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      2015\n",
      "           1       0.81      0.80      0.81      1825\n",
      "\n",
      "    accuracy                           0.82      3840\n",
      "   macro avg       0.82      0.82      0.82      3840\n",
      "weighted avg       0.82      0.82      0.82      3840\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.61628073, 0.13477637]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.17807277, 0.40302372]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.39643577, 0.31734306]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8687469 , 0.09912923]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2697211 , 0.44144568]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4811595, 0.3211596]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.27243468, 0.39943507]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.55192226, 0.16574962]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.30914125, 0.41968182]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.69165057, 0.15755893]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7866819 , 0.06584659]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.08432576, 0.47341612]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN6.hdf5')\n",
    "\n",
    "y_train_pred = model.predict(X_train_images)\n",
    "y_test_pred  = model.predict(X_test_images)\n",
    "\n",
    "y_train_pred2 = np.argmax(y_train_pred, axis=1).reshape(-1,1)\n",
    "y_test_pred2 = np.argmax(y_test_pred, axis=1).reshape(-1,1)\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b956a666-4156-4412-9c40-b23a94c0d65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 20s 47ms/step\n",
      "120/120 [==============================] - 5s 45ms/step\n",
      "Kappa score: 0.8206517469959245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      7317\n",
      "           1       0.93      0.87      0.90      6295\n",
      "\n",
      "    accuracy                           0.91     13612\n",
      "   macro avg       0.91      0.91      0.91     13612\n",
      "weighted avg       0.91      0.91      0.91     13612\n",
      "\n",
      "Kappa score: 0.6852106970311183\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86      2015\n",
      "           1       0.86      0.80      0.83      1825\n",
      "\n",
      "    accuracy                           0.84      3840\n",
      "   macro avg       0.85      0.84      0.84      3840\n",
      "weighted avg       0.84      0.84      0.84      3840\n",
      "\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.16362569]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.51651347]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.77879155]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06761437]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.80964977]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.38393688]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.32172388]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00436076]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6356337]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00274541]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00271719]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5337915]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN7.hdf5')\n",
    "\n",
    "y_train_pred = model.predict(X_train_images)\n",
    "y_test_pred  = model.predict(X_test_images)\n",
    "\n",
    "y_train_pred2 = [int(round(y_train_pred[x][0],0)) for x in range(len(y_train_pred))]\n",
    "y_test_pred2 = [int(round(y_test_pred[x][0],0)) for x in range(len(y_test_pred))]\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a566205d-f9c0-4896-bf0a-298c37dcd023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 17s 39ms/step\n",
      "120/120 [==============================] - 6s 46ms/step\n",
      "Kappa score: 0.7329338881361253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87      7317\n",
      "           1       0.84      0.88      0.86      6295\n",
      "\n",
      "    accuracy                           0.87     13612\n",
      "   macro avg       0.87      0.87      0.87     13612\n",
      "weighted avg       0.87      0.87      0.87     13612\n",
      "\n",
      "Kappa score: 0.5919351161199962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80      2015\n",
      "           1       0.77      0.80      0.79      1825\n",
      "\n",
      "    accuracy                           0.80      3840\n",
      "   macro avg       0.80      0.80      0.80      3840\n",
      "weighted avg       0.80      0.80      0.80      3840\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.44438887]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02164423]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9997236]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6715678]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.83996594]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.895308]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4640497]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.34878325]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.35067052]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01623635]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00101256]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9530199]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN8.hdf5')\n",
    "\n",
    "y_train_pred = model.predict(X_train_images)\n",
    "y_test_pred  = model.predict(X_test_images)\n",
    "\n",
    "y_train_pred2 = [int(round(y_train_pred[x][0],0)) for x in range(len(y_train_pred))]\n",
    "y_test_pred2 = [int(round(y_test_pred[x][0],0)) for x in range(len(y_test_pred))]\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "197e9df7-1721-4645-b418-f0059ac5003f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 16s 37ms/step\n",
      "120/120 [==============================] - 5s 42ms/step\n",
      "Kappa score: 0.7249522532921188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88      7317\n",
      "           1       0.87      0.83      0.85      6295\n",
      "\n",
      "    accuracy                           0.86     13612\n",
      "   macro avg       0.86      0.86      0.86     13612\n",
      "weighted avg       0.86      0.86      0.86     13612\n",
      "\n",
      "Kappa score: 0.6105630625411491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      2015\n",
      "           1       0.81      0.77      0.79      1825\n",
      "\n",
      "    accuracy                           0.81      3840\n",
      "   macro avg       0.81      0.80      0.81      3840\n",
      "weighted avg       0.81      0.81      0.81      3840\n",
      "\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.33120194, 0.6343772 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.83777905, 0.11902095]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02092654, 0.8883459 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3234418 , 0.41438407]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3225148 , 0.42529425]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5570909, 0.2323999]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3967304 , 0.22768113]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.35527548, 0.4459674 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.30175805, 0.2306424 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.96229213, 0.02005806]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.98544717, 0.01047089]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.15202692, 0.8229698 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN9.hdf5')\n",
    "\n",
    "y_train_pred = model.predict(X_train_images)\n",
    "y_test_pred  = model.predict(X_test_images)\n",
    "\n",
    "y_train_pred2 = np.argmax(y_train_pred, axis=1).reshape(-1,1)\n",
    "y_test_pred2 = np.argmax(y_test_pred, axis=1).reshape(-1,1)\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "25faafbb-d7c2-4ce9-a1bd-7cf96ac15a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 17s 40ms/step\n",
      "120/120 [==============================] - 4s 37ms/step\n",
      "Kappa score: 0.7406782551475342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      7317\n",
      "           1       0.85      0.87      0.86      6295\n",
      "\n",
      "    accuracy                           0.87     13612\n",
      "   macro avg       0.87      0.87      0.87     13612\n",
      "weighted avg       0.87      0.87      0.87     13612\n",
      "\n",
      "Kappa score: 0.5999798727905967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      2015\n",
      "           1       0.79      0.79      0.79      1825\n",
      "\n",
      "    accuracy                           0.80      3840\n",
      "   macro avg       0.80      0.80      0.80      3840\n",
      "weighted avg       0.80      0.80      0.80      3840\n",
      "\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.91418284]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06656773]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9961306]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.50484955]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.76812255]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.73173606]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.93292]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.422247]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.51066226]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.6653236e-06]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.6900859e-06]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9794125]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN10.hdf5')\n",
    "\n",
    "y_train_pred = model.predict(X_train_images)\n",
    "y_test_pred  = model.predict(X_test_images)\n",
    "\n",
    "y_train_pred2 = [int(round(y_train_pred[x][0],0)) for x in range(len(y_train_pred))]\n",
    "y_test_pred2 = [int(round(y_test_pred[x][0],0)) for x in range(len(y_test_pred))]\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "be144a5d-3882-4a6f-a8cd-032e29113aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 16s 38ms/step\n",
      "120/120 [==============================] - 5s 39ms/step\n",
      "Kappa score: 0.6785200661452317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      7317\n",
      "           1       0.84      0.81      0.82      6295\n",
      "\n",
      "    accuracy                           0.84     13612\n",
      "   macro avg       0.84      0.84      0.84     13612\n",
      "weighted avg       0.84      0.84      0.84     13612\n",
      "\n",
      "Kappa score: 0.5679992808704737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      2015\n",
      "           1       0.78      0.76      0.77      1825\n",
      "\n",
      "    accuracy                           0.78      3840\n",
      "   macro avg       0.78      0.78      0.78      3840\n",
      "weighted avg       0.78      0.78      0.78      3840\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6406086]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4598151]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99727935]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.41300726]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.71606326]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9443553]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.21612847]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.658705]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.04200867]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.07762421]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0098795]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8202972]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model('../Models/Gender_NN11.hdf5')\n",
    "\n",
    "y_train_pred = model.predict(X_train_images)\n",
    "y_test_pred  = model.predict(X_test_images)\n",
    "\n",
    "y_train_pred2 = [int(round(y_train_pred[x][0],0)) for x in range(len(y_train_pred))]\n",
    "y_test_pred2 = [int(round(y_test_pred[x][0],0)) for x in range(len(y_test_pred))]\n",
    "\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_train_gender, y_train_pred2))\n",
    "print(classification_report(y_train_gender, y_train_pred2, zero_division = True))\n",
    "print(\"Kappa score:\",cohen_kappa_score(y_test_gender, y_test_pred2))\n",
    "print(classification_report(y_test_gender, y_test_pred2, zero_division = True))\n",
    "\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Alfon3.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Cande.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ignacio.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Lydia2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Mama.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Paz2.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Pilar.jpg\")])))\n",
    "display(model.predict(np.array([image_preprocess(\"../Data/Test/Ra.jpg\")])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
